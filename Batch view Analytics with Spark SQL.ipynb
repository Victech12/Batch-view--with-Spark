{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4b1b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_file = sc.textFile(\"file:///home/victorbdm/assignment_data/*.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea4fe850",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_file = r_file.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bf998e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_quotation(x):\n",
    "    return([xx.replace('\"', '') for xx in x])\n",
    "r_file = r_file.map(remove_quotation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078dd49c",
   "metadata": {},
   "source": [
    "#### Removing of NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c40490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_file = r_file.filter(lambda x:'NA' not in x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc8a936",
   "metadata": {},
   "source": [
    "##### Loading Spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e76a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fileDF = spark.createDataFrame(data = r_file.filter(lambda x:x[0]!= 'date'),\n",
    "                                  schema = r_file.filter(lambda x:x[0]=='date').collect()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910cca29",
   "metadata": {},
   "source": [
    "#### Importing  libraries and variable conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "945c53ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0aba6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fileDF = r_fileDF.withColumn(\"date\", r_fileDF[\"date\"].cast(DateType()))\n",
    "r_fileDF = r_fileDF.withColumn(\"size\", r_fileDF[\"size\"].cast(IntegerType()))\n",
    "r_fileDF = r_fileDF.withColumn(\"ip_id\", r_fileDF[\"ip_id\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c912cca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_fileDF.createOrReplaceTempView('packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27915946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- size: integer (nullable = true)\n",
      " |-- r_version: string (nullable = true)\n",
      " |-- r_arch: string (nullable = true)\n",
      " |-- r_os: string (nullable = true)\n",
      " |-- package: string (nullable = true)\n",
      " |-- version: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- ip_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_fileDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbe4da6",
   "metadata": {},
   "source": [
    "#### 1. Total number of download for ggplot and dplyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ecea57be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|package|package_count|\n",
      "+-------+-------------+\n",
      "|  dplyr|        13369|\n",
      "|ggplot2|        39295|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gd_package = spark.sql('SELECT package, COUNT(package) AS package_count FROM packages WHERE package in (\"ggplot2\", \"dplyr\") GROUP BY package ORDER BY package_count')\n",
    "gd_package.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1a9a5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_package.select(\"package\", \"package_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"gd_package\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbb806d",
   "metadata": {},
   "source": [
    "#### 2. Total download by each operating system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a38ef9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+\n",
      "|           r_os|os_count|\n",
      "+---------------+--------+\n",
      "|        mingw32| 1111764|\n",
      "|      linux-gnu|  519725|\n",
      "|     darwin17.0|  364260|\n",
      "|       darwin20|   43771|\n",
      "|   darwin15.6.0|   25604|\n",
      "|   darwin13.4.0|    5675|\n",
      "|   darwin20.6.0|    3178|\n",
      "|   darwin20.4.0|    1434|\n",
      "|     linux-musl|    1040|\n",
      "|   darwin19.6.0|     708|\n",
      "|   darwin21.1.0|     329|\n",
      "|linux-gnueabihf|     301|\n",
      "|   darwin20.5.0|      85|\n",
      "|   darwin20.3.0|      83|\n",
      "|   darwin19.5.0|      64|\n",
      "|   darwin20.2.0|      60|\n",
      "|   darwin18.7.0|      42|\n",
      "|   darwin20.1.0|      31|\n",
      "|   darwin11.4.2|      20|\n",
      "|   darwin19.2.0|       6|\n",
      "+---------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os_package = spark.sql('SELECT r_os, COUNT(r_os) AS os_count FROM packages GROUP BY r_os ORDER BY os_count DESC')\n",
    "os_package.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5cc71c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_package.select(\"r_os\", \"os_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"os_package\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc30915",
   "metadata": {},
   "source": [
    "#### 3. Top 10 distinct large package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44541e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+\n",
      "|  package|package_size|\n",
      "+---------+------------+\n",
      "|      h2o|   178032483|\n",
      "|gdalcubes|   113334894|\n",
      "|    terra|   112345795|\n",
      "|       sf|   106864613|\n",
      "|    rgdal|   104486593|\n",
      "|   vapour|   101826642|\n",
      "|     apcf|    98560474|\n",
      "|     Boom|    84741330|\n",
      "|   mlpack|    60423534|\n",
      "|    torch|    49660349|\n",
      "+---------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_package = spark.sql('SELECT DISTINCT package, MAX(size) AS package_size FROM packages GROUP BY package ORDER BY package_size DESC ')\n",
    "top_package.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4b73ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_package.select(\"package\", \"package_size\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"top_package\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d72e79",
   "metadata": {},
   "source": [
    "#### 4. Top 10 least popular package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "272ee5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+\n",
      "|     package|package_count|\n",
      "+------------+-------------+\n",
      "|      cuml4r|            1|\n",
      "|     lazyrmd|            2|\n",
      "| c2d4u.tools|            2|\n",
      "|       CommT|            2|\n",
      "|        exif|            2|\n",
      "|    idmTPreg|            2|\n",
      "|heatmap.plus|            2|\n",
      "| packagedocs|            2|\n",
      "|   gitgadget|            2|\n",
      "|        bspm|            2|\n",
      "+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "least_package = spark.sql('SELECT DISTINCT package, COUNT(package) AS package_count FROM packages GROUP BY package ORDER BY package_count ASC')\n",
    "least_package.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0a9b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "least_package.select(\"package\", \"package_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"least_package\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96169022",
   "metadata": {},
   "source": [
    "#### 5. Most downloading hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7595108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|    time|time_count|\n",
      "+--------+----------+\n",
      "|04:47:56|       205|\n",
      "+--------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "download_time = spark.sql('SELECT time, COUNT(time) AS time_count FROM packages GROUP BY time ORDER BY time_count DESC')\n",
    "download_time.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27b764da",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_time.select(\"time\", \"time_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"download_time\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d44fe4f",
   "metadata": {},
   "source": [
    "#### 6. Top 5 package in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5939fcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------------+\n",
      "|country| package|package_count|\n",
      "+-------+--------+-------------+\n",
      "|     US|  crayon|         7956|\n",
      "|     US|   rlang|         7604|\n",
      "|     US|     cli|         6979|\n",
      "|     US|   vctrs|         6408|\n",
      "|     US|ellipsis|         6389|\n",
      "+-------+--------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_package = spark.sql('SELECT country, package, COUNT(package) AS package_count FROM packages WHERE country= \"US\" GROUP BY package, country ORDER BY package_count DESC')\n",
    "us_package.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "53782f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_package.select(\"country\", \"package\", \"package_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"us_package\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb523a",
   "metadata": {},
   "source": [
    "#### 7. Packages downloaded by the machine with higher download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27e6dce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|    package|package_download|\n",
      "+-----------+----------------+\n",
      "|       ragg|           50700|\n",
      "|textshaping|           50306|\n",
      "|    ggplot2|           38809|\n",
      "|   devtools|           28498|\n",
      "|      Hmisc|           28216|\n",
      "|         sf|           26546|\n",
      "|      units|           26120|\n",
      "|      rgeos|           25525|\n",
      "|    pkgdown|           25279|\n",
      "|        cli|           17403|\n",
      "|      rlang|           17321|\n",
      "|     crayon|           15115|\n",
      "|  lifecycle|           13301|\n",
      "|     pillar|           13234|\n",
      "|     tibble|           13220|\n",
      "|      dplyr|           12950|\n",
      "|      vctrs|           12891|\n",
      "|   ellipsis|           12745|\n",
      "|       glue|           11844|\n",
      "|   magrittr|           11761|\n",
      "+-----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "machine_package = spark.sql('SELECT package, count(package) AS package_download FROM packages WHERE r_arch = (SELECT max(r_arch) FROM packages) GROUP BY package order by package_download desc')\n",
    "machine_package.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01b087ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_package.select(\"package\", \"package_download\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"machine_package\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48e42a",
   "metadata": {},
   "source": [
    "#### 8. Top 3 OS used by R programmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "275143a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|      r_os|os_count|\n",
      "+----------+--------+\n",
      "|   mingw32| 1111764|\n",
      "| linux-gnu|  519725|\n",
      "|darwin17.0|  364260|\n",
      "+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popular_os = spark.sql('SELECT r_os, COUNT(r_os) AS os_count FROM packages GROUP BY r_os ORDER BY os_count DESC')\n",
    "popular_os.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e2edca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_os.select(\"r_os\", \"os_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"popular_os\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbb8393",
   "metadata": {},
   "source": [
    "#### 9. R user that uses 32 bit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c5496c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+\n",
      "|r_arch|machine_count|\n",
      "+------+-------------+\n",
      "|  i386|        27317|\n",
      "+------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "r_32bit = spark.sql('SELECT r_arch, COUNT(r_arch) AS machine_count FROM packages WHERE r_arch=\"i386\" GROUP BY r_arch ORDER BY machine_count DESC')\n",
    "r_32bit.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb481bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_32bit.select(\"r_arch\", \"machine_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"r_32bit\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcfb68c",
   "metadata": {},
   "source": [
    "#### 10. Total download by each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08201254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|country|country_count|\n",
      "+-------+-------------+\n",
      "|     PW|            1|\n",
      "|     AD|            1|\n",
      "|     TC|            1|\n",
      "|     SR|            2|\n",
      "|     CV|            3|\n",
      "|     AP|            3|\n",
      "|     LR|            3|\n",
      "|     LI|            3|\n",
      "|     GA|            3|\n",
      "|     MC|            3|\n",
      "|     SB|            4|\n",
      "|     MD|            5|\n",
      "|     BM|            6|\n",
      "|     YE|            6|\n",
      "|     RE|            6|\n",
      "|     KG|            7|\n",
      "|     BB|            8|\n",
      "|     SO|            8|\n",
      "|     DM|            8|\n",
      "|     A2|           18|\n",
      "+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "country = spark.sql('SELECT DISTINCT country, COUNT(country) AS country_count FROM packages GROUP BY country ORDER BY country_count ASC')\n",
    "country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "da449403",
   "metadata": {},
   "outputs": [],
   "source": [
    "country.select(\"country\", \"country_count\")\\\n",
    ".write.format(\"org.apache.spark.sql.cassandra\")\\\n",
    ".options(table=\"country\", keyspace=\"assignment2\")\\\n",
    ".save(mode=\"append\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681ac416",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
